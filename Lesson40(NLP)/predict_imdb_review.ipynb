{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer\n",
    "from sklearn.feature_extraction.text  import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(dtype='uint8', binary=True)\n",
    "\n",
    "cv.fit(df['review'])\n",
    "dataset_x = cv.transform(df['review']).todense()\n",
    "dataset_y = (df['sentiment'] == 'positive').to_numpy(dtype='uint8') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without CountVectorizer\n",
    "vocab =  set()\n",
    "import re\n",
    "\n",
    "for text in df['review']:\n",
    "    words = re.findall('[a-zA-Z0-9]+', text.lower())\n",
    "    vocab.update(words)\n",
    "\n",
    "vocab_dict = {word: index for index, word in enumerate(vocab)}\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "dataset_x = np.zeros((len(df), len(vocab)), dtype='uint8')  \n",
    "for row, text in enumerate(df['review']):\n",
    "    words = re.findall('[a-zA-Z0-9]+', text.lower())\n",
    "    word_numbers = [vocab_dict[word] for word in words]\n",
    "    dataset_x[row, word_numbers] = 1\n",
    "\n",
    "dataset_y = (df['sentiment'] == 'positive').to_numpy(dtype='uint8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name='IMDB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Input((training_dataset_x.shape[1],)))\n",
    "model.add(Dense(128, activation='relu', name='Hidden-1'))\n",
    "model.add(Dense(128, activation='relu', name='Hidden-2'))\n",
    "model.add(Dense(1, activation='sigmoid', name='Output'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "hist = model.fit(training_dataset_x, training_dataset_y, batch_size=32, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "plt.title('Epoch - Loss Graph', pad=10, fontsize=14)\n",
    "plt.xticks(range(0, 300, 10))\n",
    "plt.plot(hist.epoch, hist.history['loss'])\n",
    "plt.plot(hist.epoch, hist.history['val_loss'])\n",
    "plt.legend(['Loss', 'Validation Loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "plt.title('Epoch - Binary Accuracy Graph', pad=10, fontsize=14)\n",
    "plt.xticks(range(0, 300, 10))\n",
    "plt.plot(hist.epoch, hist.history['binary_accuracy'])\n",
    "plt.plot(hist.epoch, hist.history['val_binary_accuracy'])\n",
    "plt.legend(['Accuracy', 'Validation Accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = model.evaluate(test_dataset_x, test_dataset_y, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(eval_result)):\n",
    "    print(f'{model.metrics_names[i]}: {eval_result[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "predict_df = pd.read_csv('predict-imdb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dataset_x = np.zeros((len(predict_df), len(vocab)))\n",
    "for row, text in enumerate(predict_df['review']):\n",
    "    words = re.findall('[a-zA-Z0-9]+', text.lower())\n",
    "    word_numbers = [vocab_dict[word] for word in words]\n",
    "    predict_dataset_x[row, word_numbers] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For CountVectorizer\n",
    "predict_dataset_x = cv.transform(predict_df['review']).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result = model.predict(predict_dataset_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for presult in predict_result[:, 0]:\n",
    "    if (presult > 0.5):\n",
    "        print('Positive')\n",
    "    else:\n",
    "        print('Negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_x'teki birinci yorumun yazı haline getirilmesi\n",
    "rev_vocab_dict = {index: word for word, index in vocab_dict.items()}\n",
    "\n",
    "word_indices = np.argwhere(dataset_x[0] == 1).flatten()\n",
    "words = [rev_vocab_dict[index] for index in word_indices]\n",
    "text = ' '.join(words)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_x'teki birinci yorumun yazı haline getirilmesi\n",
    "import numpy as np\n",
    "\n",
    "rev_vocab_dict = {index: word for word, index in cv.vocabulary_.items()}\n",
    "\n",
    "word_indices = np.argwhere(dataset_x[0] == 1)[:, 1]\n",
    "words = [rev_vocab_dict[index] for index in word_indices]\n",
    "text = ' '.join(words)\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
